{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing the data files\n",
    "\n",
    "Here we convert the triplets data into dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_file = 'xaa.txt'\n",
    "header_list = [\"listenerID\", \"songID\", \"count\"]\n",
    "df = pd.read_csv(main_file, sep='\\t', names=header_list)\n",
    "df_2 = pd.read_csv('test_triplets_first_half.txt', sep='\\t', names=header_list)\n",
    "df = pd.concat([df, df_2], ignore_index= True)\n",
    "# Grouping and getting sets of songs for each user along with total number of plays\n",
    "df_group_listeners_count = df.groupby('listenerID')['songID'].agg(size=len, set=lambda x: set(x))\n",
    "# Grouping and getting lists of songs for each user along with total number of plays\n",
    "df_group_listeners = df.groupby('listenerID')[['songID', 'count']].apply(lambda g: g.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will be used to create dictionaries from list\n",
    "def get_dict_from_list(temp):\n",
    "    songs_dict = {}\n",
    "    count = 0\n",
    "    for item in temp:\n",
    "        count += item[1]\n",
    "    for item in temp:\n",
    "        songs_dict[item[0]] = item[1] / count\n",
    "    return songs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listenersSongs is a dictionary of user_id as keys and dictionaries with song_ID keys and percentage played as values\n",
    "listenersSongs = df_group_listeners.apply(lambda row: get_dict_from_list(row)).to_dict()\n",
    "# This will have total songs played by each user\n",
    "listenersTotalPlays = df_group_listeners_count.to_dict()['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will have listener IDs to be tested\n",
    "test_listeners = set(\n",
    "    pd.read_csv('test_triplets_first_half.txt', sep='\\t', names=header_list)['listenerID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at a random sample from the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ec200d3fd65aac3f9ba8d5e9d0c7cc8376df4f0c',\n",
      " {'SOACXET12AB01852E3': 0.0051813471502590676,\n",
      "  'SOAJZYT12AB018AE46': 0.0051813471502590676,\n",
      "  'SOAKMDU12A8C1346A9': 0.015544041450777202,\n",
      "  'SOANUKH12AB0182B83': 0.0051813471502590676,\n",
      "  'SOAUNAX12AB01876D0': 0.010362694300518135,\n",
      "  'SOAXGDH12A8C13F8A1': 0.02072538860103627,\n",
      "  'SOBAAAB12A6D4F95A5': 0.0051813471502590676,\n",
      "  'SOBDVAK12AC90759A2': 0.0051813471502590676,\n",
      "  'SOBEBRO12A8C13A69E': 0.0051813471502590676,\n",
      "  'SOBIMTY12A6D4F931F': 0.0051813471502590676,\n",
      "  'SOBOGML12AB017FEEC': 0.0051813471502590676,\n",
      "  'SOBPWRJ12A8C132C2D': 0.0051813471502590676,\n",
      "  'SOBSKOP12AF72A24AD': 0.0051813471502590676,\n",
      "  'SOBUBLL12A58A795A8': 0.02072538860103627,\n",
      "  'SOBUXNB12AB0182BF3': 0.0051813471502590676,\n",
      "  'SOBWLMV12AF72A7B1E': 0.0051813471502590676,\n",
      "  'SOCRFPY12A8C134E04': 0.0051813471502590676,\n",
      "  'SOCTOZW12A8C13AE90': 0.0051813471502590676,\n",
      "  'SOCYZRT12AB018506D': 0.0051813471502590676,\n",
      "  'SODBORG12A8C133BC2': 0.0051813471502590676,\n",
      "  'SODLAPJ12A8C142002': 0.031088082901554404,\n",
      "  'SODRVBA12A58A7F235': 0.0051813471502590676,\n",
      "  'SODUANR12A6D4F5036': 0.0051813471502590676,\n",
      "  'SODUQLE12AF72A0F05': 0.02072538860103627,\n",
      "  'SOEBSTQ12A8C13CFBC': 0.0051813471502590676,\n",
      "  'SOEDLKD12A8C1381F9': 0.010362694300518135,\n",
      "  'SOEMLAM12A8C1422C0': 0.0051813471502590676,\n",
      "  'SOEOJHS12AB017F3DC': 0.015544041450777202,\n",
      "  'SOEQLJP12AB018FBC5': 0.025906735751295335,\n",
      "  'SOEYYLH12A8C1330FE': 0.0051813471502590676,\n",
      "  'SOFFCOP12A8C1422E3': 0.0051813471502590676,\n",
      "  'SOFJJYX12A8C13E821': 0.0051813471502590676,\n",
      "  'SOFLJIY12A8C13FF69': 0.0051813471502590676,\n",
      "  'SOFLLNJ12A6D4FA78A': 0.015544041450777202,\n",
      "  'SOFPCZP12A8C136B4F': 0.02072538860103627,\n",
      "  'SOFQFWN12A58A7A84E': 0.0051813471502590676,\n",
      "  'SOFSSVK12A6D4FA7B5': 0.0051813471502590676,\n",
      "  'SOFVHLF12A8C140E48': 0.0051813471502590676,\n",
      "  'SOFWNCW12A8151B81A': 0.010362694300518135,\n",
      "  'SOGDQWF12A67AD954F': 0.0051813471502590676,\n",
      "  'SOGEAYR12A6D4F89B0': 0.0051813471502590676,\n",
      "  'SOGEFOF12A81C2235D': 0.0051813471502590676,\n",
      "  'SOGISVQ12A8C13AE9B': 0.0051813471502590676,\n",
      "  'SOGJDAO12AB0182AFA': 0.0051813471502590676,\n",
      "  'SOGKHRQ12AF72A4231': 0.0051813471502590676,\n",
      "  'SOGOMCI12AB0188C6C': 0.0051813471502590676,\n",
      "  'SOGVTEY12AC90754F7': 0.0051813471502590676,\n",
      "  'SOHIDLH12AC3DFB773': 0.0051813471502590676,\n",
      "  'SOHNOOC12A8C13BF35': 0.0051813471502590676,\n",
      "  'SOHVEID12AC960A131': 0.0051813471502590676,\n",
      "  'SOHVMRR12AB01810CD': 0.010362694300518135,\n",
      "  'SOIEYZO12AB0188717': 0.0051813471502590676,\n",
      "  'SOIHEZR12AB0182B79': 0.015544041450777202,\n",
      "  'SOIMTFP12AC907599E': 0.010362694300518135,\n",
      "  'SOIRBTN12A8C13C97B': 0.0051813471502590676,\n",
      "  'SOJCAVK12A8151B805': 0.0051813471502590676,\n",
      "  'SOJFRIL12A6D4FB684': 0.0051813471502590676,\n",
      "  'SOJLZQH12AC9075519': 0.0051813471502590676,\n",
      "  'SOJNWFM12A8C13AB16': 0.0051813471502590676,\n",
      "  'SOJUTHQ12AB01841F1': 0.0051813471502590676,\n",
      "  'SOKDFZW12AC9072C8C': 0.0051813471502590676,\n",
      "  'SOKFNBL12AF72A1A41': 0.0051813471502590676,\n",
      "  'SOKUGOT12A58A7CC62': 0.0051813471502590676,\n",
      "  'SOKUIUK12A8C13F7F0': 0.010362694300518135,\n",
      "  'SOKUOGD12A8C13ECC3': 0.0051813471502590676,\n",
      "  'SOKXQDO12AB017FD04': 0.0051813471502590676,\n",
      "  'SOKZKDF12A6D4FA670': 0.0051813471502590676,\n",
      "  'SOLJIQB12A8C13ECCB': 0.0051813471502590676,\n",
      "  'SOLKDKP12AC9072C74': 0.0051813471502590676,\n",
      "  'SOLOZRE12A8C133256': 0.0051813471502590676,\n",
      "  'SOLVTSK12AB017EFCC': 0.0051813471502590676,\n",
      "  'SOLYUTM12AB018C192': 0.0051813471502590676,\n",
      "  'SOLZKLE12AF729F385': 0.0051813471502590676,\n",
      "  'SOMGPML12A8C13AE8C': 0.0051813471502590676,\n",
      "  'SOMIWVJ12A8C13C1B5': 0.0051813471502590676,\n",
      "  'SOMLECN12AAF3B46F6': 0.015544041450777202,\n",
      "  'SOMRTFI12AB01821EE': 0.0051813471502590676,\n",
      "  'SONBNVV12A8151B825': 0.0051813471502590676,\n",
      "  'SONNSYV12A8C146BEC': 0.0051813471502590676,\n",
      "  'SONOTLL12AB018DE16': 0.0051813471502590676,\n",
      "  'SONPLUD12A8C13BF4B': 0.0051813471502590676,\n",
      "  'SONXCYX12AB0184785': 0.0051813471502590676,\n",
      "  'SOOEXHQ12AB0182BC5': 0.010362694300518135,\n",
      "  'SOOSDMO12A6D4F80F9': 0.010362694300518135,\n",
      "  'SOOUXUD12AB0188D97': 0.0051813471502590676,\n",
      "  'SOOXJDU12A8AE47ECB': 0.0051813471502590676,\n",
      "  'SOOXUMZ12A6D4F8429': 0.0051813471502590676,\n",
      "  'SOPHOKZ12A8C13C4FA': 0.0051813471502590676,\n",
      "  'SOQDMED12A67ADE731': 0.0051813471502590676,\n",
      "  'SOQPYOA12AB0186DB8': 0.0051813471502590676,\n",
      "  'SOQQRXS12AF72A186D': 0.0051813471502590676,\n",
      "  'SOQSPDJ12A58A7EC6E': 0.0051813471502590676,\n",
      "  'SOQXTDZ12AF729F8B4': 0.0051813471502590676,\n",
      "  'SORFVMQ12AB0184135': 0.010362694300518135,\n",
      "  'SORJAAY12AB018A172': 0.0051813471502590676,\n",
      "  'SORKMJX12A8C13CFA1': 0.0051813471502590676,\n",
      "  'SORQMDK12A6D4FAF77': 0.0051813471502590676,\n",
      "  'SORWJHX12AB01878BA': 0.010362694300518135,\n",
      "  'SORWPCP12A8C13B9D8': 0.010362694300518135,\n",
      "  'SORXTFK12AB018A177': 0.0051813471502590676,\n",
      "  'SOSACAB12AB01876E4': 0.0051813471502590676,\n",
      "  'SOSVQPX12A8C14078C': 0.0051813471502590676,\n",
      "  'SOSZESM12AB01810BF': 0.010362694300518135,\n",
      "  'SOTGHAO12AB0183D03': 0.0051813471502590676,\n",
      "  'SOTGHQR12A8C1406C5': 0.031088082901554404,\n",
      "  'SOTGZIH12A8C1428A5': 0.0051813471502590676,\n",
      "  'SOTKFFF12AC9072C86': 0.0051813471502590676,\n",
      "  'SOTRNEF12A8C135518': 0.0051813471502590676,\n",
      "  'SOTURXT12AF72A4416': 0.0051813471502590676,\n",
      "  'SOUBHBQ12A6D4FB6B8': 0.02072538860103627,\n",
      "  'SOUEGBF12AB017EFD5': 0.010362694300518135,\n",
      "  'SOUFNSM12A58A77715': 0.0051813471502590676,\n",
      "  'SOUHQHP12AB017FCA7': 0.0051813471502590676,\n",
      "  'SOUIVPB12AC90719FA': 0.015544041450777202,\n",
      "  'SOUNODI12A8AE4730A': 0.0051813471502590676,\n",
      "  'SOUQNGY12A81C2237B': 0.0051813471502590676,\n",
      "  'SOUTHYF12A8C13C97F': 0.0051813471502590676,\n",
      "  'SOUTICS12A8C13C96C': 0.0051813471502590676,\n",
      "  'SOUYMPF12A58A7C78A': 0.0051813471502590676,\n",
      "  'SOUYTKI12AB018AF65': 0.0051813471502590676,\n",
      "  'SOVCUAX12AB017EFB5': 0.0051813471502590676,\n",
      "  'SOVDWCE12A8C13ECB9': 0.0051813471502590676,\n",
      "  'SOVOHCH12AB0184593': 0.0051813471502590676,\n",
      "  'SOVRGXP12AB017D2B9': 0.010362694300518135,\n",
      "  'SOVZWSE12A8C140F2C': 0.0051813471502590676,\n",
      "  'SOWKVVW12A8AE45E8C': 0.0051813471502590676,\n",
      "  'SOWNRRW12A58A801BA': 0.0051813471502590676,\n",
      "  'SOWSSRH12A58A7CE5D': 0.0051813471502590676,\n",
      "  'SOXAIMS12A8C137E90': 0.010362694300518135,\n",
      "  'SOXFXDH12A8C13326E': 0.0051813471502590676,\n",
      "  'SOXTGVB12A6D4F8199': 0.0051813471502590676,\n",
      "  'SOYONCL12A8C13B9F7': 0.0051813471502590676,\n",
      "  'SOYUFEX12AB0182255': 0.0051813471502590676,\n",
      "  'SOZLIOT12AC3DF97E0': 0.010362694300518135,\n",
      "  'SOZRLJL12A8C14415F': 0.0051813471502590676,\n",
      "  'SOZVBRS12A58A7803F': 0.0051813471502590676}]\n",
      "['e7d08ed33e596ec2e188785db33f950a215c99b4', 32]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0057fcc3172bc4ebf2001f5a145d17140fd97757',\n",
       " '0041156565a6b710dd3bca618684c91ca4f12804',\n",
       " '002686bc6def481ec4647f20c0c897dd43550edd',\n",
       " '01227cde5ba13d7f56109c1decf955d4ba2e930e',\n",
       " '003dd6d8c85d98cd2c0b891fe6568e4d782dda59',\n",
       " '00e82ed9a3a608c6f0fe79fffb54357c766d4ee5',\n",
       " '007e440c481873208867bb5d71565fb592aaffca',\n",
       " '0041d170b100df47f77dd1799e7fcffaeb06ee5a',\n",
       " '00667ca20d5258121085c400b6973cb4b81f5d26',\n",
       " '0048f1b93c7c85474319cef1f7768a92982dabd8']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand1 = random.choice(list(listenersSongs.keys()))\n",
    "pprint([rand1, listenersSongs[rand1]])\n",
    "rand2 = random.choice(list(listenersTotalPlays.keys()))\n",
    "pprint([rand2, listenersTotalPlays[random.choice(list(listenersTotalPlays.keys()))]])\n",
    "random.sample(test_listeners, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to generate similarity and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to calculate score from two song percentages\n",
    "def calc_common_percent(perc1, perc2):\n",
    "    smaller = min(perc1, perc2)\n",
    "    larger = max(perc1, perc2)\n",
    "    return smaller + ((smaller / larger) * (larger - smaller))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For two users, for all the common songs, this function will be used to generate two scores\n",
    "# One is percentage of common songs and other is percentage of count of songs played in common\n",
    "def generate_similarity_measure(first_dict, second_dict, user_1_total_plays, user_2_total_plays, common_songs):\n",
    "    perc_common = 0.0\n",
    "    perc_count_common = 0.0\n",
    "\n",
    "    for song in common_songs:\n",
    "        user_1_play_count = first_dict[song]\n",
    "        user_2_play_count = second_dict[song]\n",
    "\n",
    "        perc_common += calc_common_percent(user_1_play_count, user_2_play_count)\n",
    "\n",
    "        p1 = user_1_play_count * user_1_total_plays\n",
    "        p2 = user_2_play_count * user_2_total_plays\n",
    "        perc_count_common += calc_common_percent(p1, p2)\n",
    "\n",
    "    return [perc_common, perc_count_common]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the main function used to generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes pre processed data and user_ids to be tested as input\n",
    "def recommend_by_similarity(test_user_ids, user_total_plays_map, user_song_percentage_map, limiting_factor, power=1):\n",
    "    recommendation_set = {}\n",
    "    count = 0\n",
    "    tot_test_ids = len(test_user_ids)\n",
    "\n",
    "    for user_1 in test_user_ids:\n",
    "        similarity_score_map = {}\n",
    "\n",
    "        count += 1\n",
    "        if count % 30 == 1 :\n",
    "            print(\"Test listener \", count, \" of \", tot_test_ids)\n",
    "\n",
    "        for user_2, user_2_songs_perc_map in user_song_percentage_map.items():\n",
    "\n",
    "            if user_1 != user_2:\n",
    "#                 Get common songs between current user and every other user\n",
    "                common_songs = {k for k in user_song_percentage_map[user_1].keys() if k in user_2_songs_perc_map}\n",
    "#                  If there are any common songs, using the song measure and other stats, generate a score for this user\n",
    "                if len(common_songs) != 0:\n",
    "                    similarity_score_map[user_2] = generate_similarity_measure(user_song_percentage_map[user_1],\n",
    "                                                                               user_2_songs_perc_map,\n",
    "                                                                               user_total_plays_map[user_1],\n",
    "                                                                               user_total_plays_map[user_2],\n",
    "                                                                               common_songs)\n",
    "\n",
    "        rescaling_factors = []\n",
    "        for i in range(2):\n",
    "            max_val = max([v[i] for v in similarity_score_map.values()])\n",
    "            factor = 1.0 / max_val if max_val != 0 else 0.0\n",
    "            rescaling_factors.append(factor)\n",
    "            \n",
    "#         Summing all the percentages for all similar songs, get a single score for all users\n",
    "\n",
    "        similarity_score_map = {k: sum(np.array(v) * np.array(rescaling_factors)) ** power for k, v in\n",
    "                                similarity_score_map.items()}\n",
    "        numRecsRequired = len(user_song_percentage_map[user_1])\n",
    "\n",
    "        maximum_similarity_score = max(similarity_score_map.values())\n",
    "\n",
    "        recommendations = {}\n",
    "\n",
    "        if count % 30 == 1 :\n",
    "            print(\"Recommending for listener, \", count)\n",
    "\n",
    "#         Sorting by highest scored user first, make recommendations\n",
    "        for user_2, similarity in sorted(similarity_score_map.items(), key=lambda x: x[1], reverse=True):\n",
    "            if len(recommendations) >= numRecsRequired and similarity < limiting_factor * maximum_similarity_score:\n",
    "                break\n",
    "#             Get songs which curr user have not listened but the other one has. Add those to recommendations\n",
    "            user1_not_listened_songs = {key: val for key, val in user_song_percentage_map[user_2].items() if\n",
    "                                        key not in user_song_percentage_map[user_1]}\n",
    "            for song_id, perc_played in user1_not_listened_songs.items():\n",
    "                if song_id not in recommendations:\n",
    "                    recommendations[song_id] = perc_played * similarity\n",
    "                else:\n",
    "                    recommendations[song_id] += perc_played * similarity\n",
    "        recommendation_set[user_1] = [k for k in sorted(recommendations, key=recommendations.get, reverse=True)]\n",
    "    print('Finished recommending')\n",
    "    return recommendation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find matched songs and get score. 0 if none\n",
    "def check_hit_count_score(actual_listened_songs, predicted_songs, threshold=10):\n",
    "    if len(predicted_songs) > threshold:\n",
    "        predicted_songs = predicted_songs[:threshold]\n",
    "    hit_score = 0.0\n",
    "    number_of_matched_songs = 0.0    \n",
    "    for index, song in enumerate(predicted_songs):\n",
    "        if song in actual_listened_songs and song not in predicted_songs[:index]:\n",
    "            number_of_matched_songs += 1.0\n",
    "            hit_score += number_of_matched_songs / (index + 1.0)\n",
    "    if not actual_listened_songs:\n",
    "        return 0.0\n",
    "    return hit_score / min(len(actual_listened_songs), threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average score\n",
    "def get_average_recommendation_score(actual_list, predicted_list, threshold=10):\n",
    "    return np.mean([check_hit_count_score(actual_song, predicted_song, threshold) for actual_song, predicted_song in\n",
    "                    zip(actual_list, predicted_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionaries to lists to conveniently genearte scores\n",
    "def calculate_whole_mean_score(recommended_songs_map, actual_songs_map):\n",
    "    recommended_songs_list = []\n",
    "    actual_songs_list = []\n",
    "    for user_id, actual_songs in actual_songs_map.items():\n",
    "        actual_songs_list.append(actual_songs)\n",
    "        recommended_songs_list.append(recommended_songs_map[user_id])\n",
    "    return get_average_recommendation_score(actual_songs_list, recommended_songs_list, 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing analysis and on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set is taken separately and split into two halves. One half of the data will be used to make predictions and the other half will be used to verify if the recommendations match the actual listened songs or not.\n",
    "\n",
    "One file is test_triplets_first_half.txt and other is test_triplets_second_half.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will have all the user_ids to be tested. \n",
    "#Songs these users listened(first half) will already be there in the training dictionaries\n",
    "test_listeners = set(\n",
    "    pd.read_csv('test_triplets_first_half.txt', sep='\\t', names=header_list)['listenerID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test listener  1  of  526\n",
      "Recommending for listener,  1\n",
      "Test listener  31  of  526\n",
      "Recommending for listener,  31\n",
      "Test listener  61  of  526\n",
      "Recommending for listener,  61\n",
      "Test listener  91  of  526\n",
      "Recommending for listener,  91\n",
      "Test listener  121  of  526\n",
      "Recommending for listener,  121\n",
      "Test listener  151  of  526\n",
      "Recommending for listener,  151\n",
      "Test listener  181  of  526\n",
      "Recommending for listener,  181\n",
      "Test listener  211  of  526\n",
      "Recommending for listener,  211\n",
      "Test listener  241  of  526\n",
      "Recommending for listener,  241\n",
      "Test listener  271  of  526\n",
      "Recommending for listener,  271\n",
      "Test listener  301  of  526\n",
      "Recommending for listener,  301\n",
      "Test listener  331  of  526\n",
      "Recommending for listener,  331\n",
      "Test listener  361  of  526\n",
      "Recommending for listener,  361\n",
      "Test listener  391  of  526\n",
      "Recommending for listener,  391\n",
      "Test listener  421  of  526\n",
      "Recommending for listener,  421\n",
      "Test listener  451  of  526\n",
      "Recommending for listener,  451\n",
      "Test listener  481  of  526\n",
      "Recommending for listener,  481\n",
      "Test listener  511  of  526\n",
      "Recommending for listener,  511\n",
      "Finished recommending\n"
     ]
    }
   ],
   "source": [
    "# Calling the main method to generate recommendations\n",
    "listenersRecs = recommend_by_similarity(test_listeners, listenersTotalPlays, listenersSongs, .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate the actual songs the user has listened to. The second half of the test set\n",
    "df_answers = pd.read_csv('test_triplets_second_half.txt', sep='\\t', names=header_list)\n",
    "actual_listened_songs_map = df_answers.groupby('listenerID')['songID'].agg(lambda x: set(x)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10311862633478829\n"
     ]
    }
   ],
   "source": [
    "# Use the formulae to calculate recommendation score\n",
    "print(calculate_whole_mean_score(listenersRecs, actual_listened_songs_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is around 10-12 for this dataset. This is almost 5 times better than recommending randomly or recommending popular songs. Still, as this is a basic type of recommendation system, accuracy can be considered low. ALS methods, which will be done sepaately will have better accuracy than this method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
